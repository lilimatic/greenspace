{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = f'/Users/lilimatic/greenspace'\n",
    "os.chdir(directory)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score  \n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, confusion_matrix, accuracy_score \n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.ml_data_hot_one import *\n",
    "\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='safety',y=df.safety,kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.safety)/len(df.safety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'safety'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_copy.loc[:, df_copy.columns != y], \\\n",
    "                                                    df_copy[y], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar proportions\n",
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train #provide your own target name\n",
    ")\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=15,max_depth=8,random_state=24,criterion='gini',min_samples_split=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model fit \n",
    "\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy: ', np.mean(rf.predict(X_train) ==y_train)*100) \n",
    "print ('Test accuracy:', np.mean(rf.predict(X_test) ==y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(model,X_test,y_test,values_format='d',display_labels=['Safe','Unsafe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob3 = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_prob3[:,1], pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auc scores\n",
    "\n",
    "auc_score3 = roc_auc_score(y_test, pred_prob3[:,1])\n",
    "\n",
    "print(auc_score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "#plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='XGB')\n",
    "plt.plot(fpr3, tpr3, linestyle='--',color='purple') #label='Random Forest'\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "\n",
    "#plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.grid(False)\n",
    "\n",
    "#ax = plt.axes()\n",
    "#ax.set_facecolor(\"white\")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf, X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.columns\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "values = list(rf.feature_importances_[indices])\n",
    "\n",
    "names = [features[i] for i in indices]\n",
    "\n",
    "importance = pd.DataFrame({'district' : names, 'importance': values})\n",
    "\n",
    "importance = importance.sort_values('district')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged will be summed \n",
    "merged = [] \n",
    "names_merged=[] \n",
    "for o in oldcolumns:\n",
    "    if (len([col for col in df if col.startswith(o+'_')])>0):\n",
    "        merged.append([col for col in df if col.startswith(o+'_')])\n",
    "        names_merged.append(o)\n",
    "\n",
    "\n",
    "sums_merged = []\n",
    "\n",
    "for m in merged:\n",
    "    #print(m)\n",
    "    sums_merged.append(importance.loc[importance['district'].isin(m)].sum()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_merged.extend(['municipalities','activity','socializing','age','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in [list_municipalities,list_activities,list_socializing]: \n",
    "    sums_merged.append(importance.loc[importance['district'].isin(list(x.columns))].sum()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_merged.extend([importance.loc[importance['district'].isin(['age'])]['importance'].iloc[0],\n",
    "importance.loc[importance['district'].isin(['time'])]['importance'].iloc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove effect of safety variable\n",
    "sums_merged= sums_merged/sum(sums_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importance.loc[importance['district'].isin(['safety'])]['importance'].iloc[0]\n",
    "\n",
    "sum(sums_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = pd.DataFrame({'variable': names_merged,'importance':sums_merged })\n",
    "\n",
    "important = important.sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important.plot.bar(x='variable',y='importance',rot=0)\n",
    "\n",
    "plt.barh(important.variable,important.importance,color='red')\n",
    "plt.grid(False)\n",
    "plt.xlabel('importance')\n",
    "plt.ylabel('variable')\n",
    "plt.axes()\n",
    "ax.set_facecolor('white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
